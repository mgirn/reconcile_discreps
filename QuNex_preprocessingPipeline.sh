The pipeline used by UZH that is described in the manuscript as the “QuNex pipeline” used the QuNex automated preprocessing pipeline found here: https://qunex.yale.edu/

The above webpage provides extensive documentation on how to reproduce this pipeline.

A summary of the Qunex pipeline as automated by the above software is as follows: 

first T1-weighted structural images were aligned by warping them to the standard Montreal Neurological Institute-152 (MNI-152) brain template in a single step, through a combination of linear and non-linear transformations via the FMRIB Software Library (FSL) linear image registration tool (FLIRT) and non-linear image registration tool (FNIRT) (Jenkinson et al., 2002). Next, FreeSurfer’s recon-all pipeline was used to segment brain-wide gray and white matter to produce individual cortical and subcortical anatomical segmentations (Reuter et al., 2012). T1w images were then converted to the Connectivity Informatics Technology Initiative (CIFTI) volume/surface ‘grayordinate’ space. 

Raw BOLD images were first motion-corrected by registering each volume in a run to the corresponding single band reference image collected at the start of each run. Next, a brain-mask was applied to exclude signal from non-brain tissue. BOLD images were then registered to the structural images via FLIRT/FNIRT. After processing in NIFTI volume space, BOLD data were converted to the CIFTI gray matter matrix by sampling from the anatomically-defined gray matter ribbon (91281 grayordinates).  

Following these minimal HCP preprocessing steps, movement scrubbing was performed. All BOLD image frames with possible movement-induced artifactual fluctuations in intensity were flagged using two criteria: frame displacement (the sum of the displacement across all six rigid body movement correction parameters) exceeding 0.5 mm (assuming 50 mm cortical sphere radius) and/or the normalized root mean square (RMS) (calculated as the RMS of differences in intensity between the current and preceding frame, computed across all voxels and divided by the mean intensity) exceeding 1.6 times the median across scans. Any frame that met one or both of these criteria, as well as the frame immediately preceding and immediately following, were discarded from further preprocessing and analyses. Subjects with more than 50% frames flagged using these criteria were excluded. Next, spatial smoothing (FWHM) of 6mm was performed. Then, a high-pass filter (threshold 0.008 Hz) was applied to the BOLD data to remove low-frequency signals due to scanner drift. Following this, in-house Matlab code was used to calculate the average variation in BOLD signal in: (1) the ventricles;  (2) deep white matter; and (3) across the whole gray matter (i.e. the global signal). These signals, as well as their first derivatives to account for delayed effects, and the motion parameters were then regressed out of the gray matter BOLD time series as nuisance variables (Power et al., 2018). Finally, a low-pass filter (threshold 0.09 Hz) was applied. 